{"meta":{"title":"Eric Websmith's Blog","subtitle":"Machine Learning","description":"","author":"Eric Websmith","url":"https://EricWebsmith.github.io","root":"/"},"pages":[{"title":"about","date":"2020-04-03T16:33:45.000Z","updated":"2020-04-03T16:34:38.715Z","comments":true,"path":"about/index.html","permalink":"https://ericwebsmith.github.io/about/index.html","excerpt":"","text":"This is all about me."}],"posts":[{"title":"Gradient Boosting Classification from Scratch","slug":"GradientBoostingClassification","date":"2020-04-19T09:12:52.000Z","updated":"2020-04-19T10:52:22.919Z","comments":true,"path":"2020/04/19/GradientBoostingClassification/","link":"","permalink":"https://ericwebsmith.github.io/2020/04/19/GradientBoostingClassification/","excerpt":"","text":"The Gradient Boosting (GB) algorithm trains a series of weak learners and each focuses on the errors the previous learners have made and tries to improve it. Together, they make a better prediction. According to Wikipedia, Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion as other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function. Prerequisite 1. Linear regression and gradient descent 2. Decision Tree 3. Gradient Boosting Regression After studying this post, you will be able to: 1. Explain gradient boosting algorithm. 2. Explain gradient boosting classification algorithm. 3. Write a gradient boosting classification from scratch The algorithmThe following plot illustrates the algorithm. (Picture taken from Youtube channel StatQuest) From the plot above, the first part is a stump, which is the log of odds of y. We then add several trees to it. In the following trees, the target is not y. Instead, the target is the residual or the true value subtracts the previous prediction. residual=true\\_value - previous\\_predictionThat is why we say in Gradient Boosting trains a series of weak learners, each focuses on the errors of the previous one. The residual predictions are multiplied by the learning rate (0.1 here) before added to the average. Here the picture looks more complicated than the one on regression. The purple ones are log of odds (l). The green ones are probabilities. We firstly calculate log of odds of y, instead of average. We then calculate probabilities using log of odds. We build a regression tree. The leaves are colored green. The leaves have residuals. We use the probability residuals to produce log-of-odds residuals or $\\gamma$. $\\gamma$ is then used to update l. This continues until we are satisfied with the results or we are running out of iterations. The Steps Step 1: Calculate the log of odds of y. This is also the first estimation of y. Here n_1 is the number of true values and n_0 of false values. l_0(x)=\\log \\frac{n_1}{n_0}For each x_i, the probability is: p_{0i}=\\frac{e^{l_{0i}}}{1+e^{l_{0i}}}The prediction is: f_{0i}=\\begin{cases} 0 & p_{0i}=0.5 \\end{cases}Step 2 for m in 1 to M: Step 2.1: Compute so-call pseudo-residuals: r_{im}=f_i-p_i Step 2.2: Fit a regression tree t_m(x) to pseudo-residuals and create terminal regions (leaves) R_{jm} for j=1...Jm Step 2.3: For each leaf of the tree, there are $p_j$ elements, compute $\\gamma$ as following equation. \\gamma_{im}=\\frac{\\sum r_{im}}{\\sum (1-r_{im-1})(r_{im-1})} (In practise, the regression tree will do this for us.) Step 2.4: Update the log of odds with learning rate $\\alpha$: l_m(x)=l_{m-1}+\\alpha \\gamma_m For each $x_i$, the probability is: p_{mi}=\\frac{e^{l_{mi}}}{1+e^{l_{mi}}}The prediction is: f_{mi}=\\begin{cases} 0 & p_{mi}=0.5 \\end{cases}Step 3. Output f_M(x) (Optional) From Gradient Boosting to Gradient Boosting ClassificationThe above knowledge is enough for writing BGR code from scratch. But I want to explain more about gradient boosting. GB is a meta-algorithm that can be applied to both regression and classification. The above one is only a specific form for regression. In the following, I will introduce the general gradient boosting algorithm and deduce GBR from GB. Let’s first look at the GB steps The Steps Input: training set \\{(x_i, y_i)\\}_{i=1}^{n}, a differentiable loss function L(y, F(x)), number of iterations M Algorithm: Step 1: Initialize model with a constant value: F_0(x)=\\underset{\\gamma}{\\operatorname{argmin}}\\sum_{i=1}^{n}L(y_i, \\gamma)Step 2 for m in 1 to M: Step 2.1: Compute so-call pseudo-residuals: r_{im}=-[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}], {F(x)=F_{m-1}(x)} Step 2.2: Fit a weak learner h_m(x) to pseudo-residuals. and create terminal regions R_{jm}, for j=1...J_m. Step 2.3: For each leaf of the tree, compute \\gamma as the following equation. \\gamma_{jm}=\\underset{\\gamma}{\\operatorname{argmin}}\\sum_{x_i \\in R_{jm}}^{n}L(y_i, F_{m-1}(x_i)+\\gamma) Step 2.4: Update the model with learning rate $\\alpha$: F_m(x)=F_{m-1}+\\alpha\\gamma_m Step 3. Output F_M(x) Lost Function: To deduce the GB to GBC, I simply define a loss function and solve the loss function in step 1, 2.1 and 2.3. We use Log of Likelihood as the loss function: L(y, F(x))=-\\sum_{i=1}^{N}(y_i* log(p) + (1-y_i)*log(1-p))Since this is a function of probability and we need a function of log of odds(l), let’s focus on the middle part and transform it into a function of l. The middle part is: -(y*\\log(p)+(1-y)*\\log(1-p)) \\\\ =-y * \\log(p) - (1-y) * \\log(1-p) \\\\ =-y\\log(p)-\\log(1-p)+y\\log(1-p) \\\\ =-y(\\log(p)-\\log(1-p))-\\log(1-p) \\\\ =-y(\\log(\\frac{p}{1-p}))-\\log(1-p) \\\\ =-y \\log(odds)-\\log(1-p)Since \\log(1-p)=log(1-\\frac{e^{log(odds)}}{1+e^{log(odds)}}) \\\\ =\\log(\\frac{1+e^l}{1+e^l}-\\frac{e^l}{1+e^l})\\\\ =\\log(\\frac{1}{1+e^l}) \\\\ =\\log(1)+\\log(1+e^l) \\\\ =-log(1+e^{\\log(odds)})We put this to the previous equation: -(y*\\log(p)+(1-y)*\\log(1-p)) \\\\ =-y\\log(odds)+\\log(1+e^{\\log(odds)}) \\\\Thus, we will have the loss function over log of odds: L=-\\sum_{i=1}^{N}(y\\log(odds)-\\log(1+e^{\\log(odds)}))For Step 1: Because the lost function is convex and at the lowest point where the derivative is zero, we have the following: \\frac{\\partial L(y, F_0)}{\\partial F_0} \\\\ =-\\frac{\\partial \\sum_{i=1}^{N}(y\\log(odds)-\\log(1+e^{\\log(odds)}))}{\\partial log(odds)} \\\\ =-\\sum_{i=1}^{n} y_i+\\sum_{i=1}^{N} \\frac{\\partial log(1+e^{log(odds)})}{\\partial log(odds)} \\\\ =-\\sum_{i=1}^{n} y_i+\\sum_{i=1}^{N} \\frac{1}{1+e^{\\log(odds)}} \\frac{\\partial (1+e^l)}{\\partial l} \\\\ =-\\sum_{i=1}^{n} y_i+\\sum_{i=1}^{N} \\frac{1}{1+e^{\\log(odds)}} \\frac{\\partial (e^l)}{\\partial l} \\\\ =-\\sum_{i=1}^{n} y_i+\\sum_{i=1}^{N} \\frac{e^l}{1+e^l} \\\\ =-\\sum_{i=1}^{n} y_i+N\\frac{e^l}{1+e^l}=0And We have: (Here p is the real probability) \\frac{e^l}{1+e^l}=\\frac{\\sum_{i=1}^{N}y_i}{N}=p \\\\ e^l=p+p*e^l \\\\ (1-p)e^l=p \\\\ e^l=\\frac{p}{1-p} \\\\ \\log(odds)=log(\\frac{p}{1-p})Such that, when log(odds)=log(p/(1-p)) or the probability is the real probability, the lost function is minimized. For Step 2.1 r_{im}=-[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}]_{F(x)=F_{m-1}(x)}=-[\\frac{\\partial (-(y_i* log(p)+(1-y_i)*log(1-p)))}{\\partial F_{m-1}(x_i)}]_{F(x)=F_{m-1}(x)}We have already taken the derivative. =y_i-F_{m-1}(x_i)For step 2.3: \\gamma_{jm}=\\underset{\\gamma}{\\operatorname{argmin}}\\sum_{x_i \\in R_{jm}}^{n}L(y_i, F_{m-1}(x_i)+\\gamma)I apply the lost function: \\gamma_{jm} \\\\ =\\underset{\\gamma}{\\operatorname{argmin}}\\sum_{x_i \\in R_{jm}}^{n}L(y_i, F_{m-1}(x_i)+\\gamma) \\\\ =\\underset{\\gamma}{\\operatorname{argmin}}\\sum_{x_i \\in R_{jm}}^{n} (-y_i * (F_{m-1}+\\gamma)+\\log(1+e^{F_{m-1}+\\gamma})) \\\\Let’s focus on the middle part -y_i * (F_{m-1}+\\gamma)+\\log(1+e^{F_{m-1}+\\gamma})Let’s use Second Order Taylor Polynomial: L(y,F+\\gamma) \\approx L(y, F)+ \\frac{d L(y, F+\\gamma)\\gamma}{d F}+\\frac{1}{2} \\frac{d^2 L(y, F+\\gamma)\\gamma^2}{d^2 F}Let’s take the derivate: \\because \\frac{d L(y, F+\\gamma)}{d\\gamma} \\approx \\frac{d L(y, F)}{d F}+\\frac{d^2 L(y, F)\\gamma}{d^2 F}=0 \\\\ \\therefore \\frac{d L(y, F)}{d F}+\\frac{d^2 L(y, F)\\gamma}{d^2 F}=0 \\\\ \\therefore \\gamma=-\\frac{\\frac{d L(y, F)}{d F}}{\\frac{d^2 L(y, F)}{d^2 F}} \\\\ \\therefore \\gamma = \\frac{y-p}{\\frac{d^2 (-y * l + \\log(1+e^l))}{d^2 l}} \\\\ \\therefore \\gamma = \\frac{y-p}{\\frac{d (-y + \\frac{e^l}{1+e^l})}{d l}} \\\\ \\therefore \\gamma = \\frac{y-p}{\\frac{d \\frac{e^l}{1+e^l}}{d l}} \\\\(The product rule (ab)’=a’ b+a b’​) \\therefore \\gamma=\\frac{y-p}{\\frac{d e^l}{dl} * \\frac{1}{1+e^l} - e^l * \\frac{d }{d l} \\frac{1}{1+e^l}} \\\\ =\\frac{y-p}{\\frac{e^l}{1+e^l}-e^l * \\frac{1}{(1+e^l)^2} \\frac{d}{dl} (1+e^l)} \\\\ =\\frac{y-p}{\\frac{e^l}{1+e^l}- \\frac{(e^l)^2}{(1+e^l)^2}} \\\\ =\\frac{y-p}{e^l+(e^l)^2-+(e^l)^2} \\\\ =\\frac{y-p}{\\frac{e^l}{(1+e^l)^2}} \\\\ =\\frac{y-p}{p(1-p)}Now we have \\gamma = \\frac{\\sum (y-p)}{\\sum p(1-p)}CodeFirstly, let’s define a data table as follows: no name likes_popcorn age favorite_color loves_troll2 0 Alex 1 10 Blue 1 1 Brunei 1 90 Green 1 2 Candy 0 30 Blue 0 3 David 1 30 Red 0 4 Eric 0 30 Green 1 5 Felicity 0 10 Blue 1 Step 1 123456789log_of_odds0&#x3D;np.log(4 &#x2F; 2)probability0&#x3D;np.exp(log_of_odds0)&#x2F;(np.exp(log_of_odds0)+1)print(f&#39;the log_of_odds is : &#123;log_of_odds0&#125;&#39;)print(f&#39;the probability is : &#123;probability0&#125;&#39;)predict0&#x3D;1print(f&#39;the prediction is : 1&#39;)n_samples&#x3D;6loss0&#x3D;-(y*np.log(probability0)+(1-y)*np.log(1-probability0)) The output is the log_of_odds is : 0.6931471805599453the probability is : 0.6666666666666666the prediction is : 1 Step 2 For Step 2, I define a function called iteration, I will call it several times. Each time we go through from Step 2.1 to Step 2.4. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748def iteration(i): #step 2.1 calculate the residuals residuals[i] = y - probabilities[i] #step 2.2 Fit a regression tree dt = DecisionTreeRegressor(max_depth=1, max_leaf_nodes=3) dt=dt.fit(X, residuals[i]) trees.append(dt.tree_) #Step 2.3 Calculate gamma leaf_indeces=dt.apply(X) print(leaf_indeces) unique_leaves=np.unique(leaf_indeces) n_leaf=len(unique_leaves) #for leaf 1 for ileaf in range(n_leaf): leaf_index=unique_leaves[ileaf] n_leaf=len(leaf_indeces[leaf_indeces==leaf_index]) previous_probability = probabilities[i][leaf_indeces==leaf_index] denominator = np.sum(previous_probability * (1-previous_probability)) igamma = dt.tree_.value[ileaf+1][0][0] * n_leaf / denominator gamma_value[i][ileaf]=igamma print(f'for leaf &#123;leaf_index&#125;, we have &#123;n_leaf&#125; related samples. and gamma is &#123;igamma&#125;') gamma[i] = [gamma_value[i][np.where(unique_leaves==index)] for index in leaf_indeces] #Step 2.4 Update F(x) log_of_odds[i+1] = log_of_odds[i] + learning_rate * gamma[i] probabilities[i+1] = np.array([np.exp(odds)/(np.exp(odds)+1) for odds in log_of_odds[i+1]]) predictions[i+1] = (probabilities[i+1]&gt;0.5)*1.0 score[i+1]=np.sum(predictions[i+1]==y) / n_samples #residuals[i+1] = y - probabilities[i+1] loss[i+1]=np.sum(-y * log_of_odds[i+1] + np.log(1+np.exp(log_of_odds[i+1]))) new_df=df.copy() new_df.columns=['name', 'popcorn','age','color','y'] new_df[f'$p_&#123;i&#125;$']=probabilities[i] new_df[f'$l_&#123;i&#125;$']=log_of_odds[i] new_df[f'$r_&#123;i&#125;$']=residuals[i] new_df[f'$\\gamma_&#123;i&#125;$']=gamma[i] new_df[f'$l_&#123;i+1&#125;$']=log_of_odds[i+1] new_df[f'$p_&#123;i+1&#125;$']=probabilities[i+1] display(new_df) dot_data = tree.export_graphviz(dt, out_file=None, filled=True, rounded=True,feature_names=X.columns) graph = graphviz.Source(dot_data) display(graph) Now Let’s call iteration 0 1iteration(0) The output is as follow: [1 2 2 2 2 1]for leaf 1, we have 2 related samples. and gamma is 1.5for leaf 2, we have 4 related samples. and gamma is -0.7499999999999998 no name popcorn age color y 𝑝0 𝑙0 𝑟0 𝛾0 𝑙1 𝑝1 0 Alex 1 10 Blue 1 0.666667 0.693147 0.333333 1.50 1.893147 0.869114 1 Brunei 1 90 Green 1 0.666667 0.693147 0.333333 -0.75 0.093147 0.523270 2 Candy 0 30 Blue 0 0.666667 0.693147 -0.666667 -0.75 0.093147 0.523270 3 David 1 30 Red 0 0.666667 0.693147 -0.666667 -0.75 0.093147 0.523270 4 Eric 0 30 Green 1 0.666667 0.693147 0.333333 -0.75 0.093147 0.523270 5 Felicity 0 10 Blue 1 0.666667 0.693147 0.333333 1.50 1.893147 0.869114 In Iteration 0, Let’s look at each step. In Step 2.1, We calculate residuals, that is $y-p_0$. In step 2.2, we fit a regression tree as above. In step 2.3, we calculate $\\gamma$. For the first leaf, we have two samples (Alex and Felicity). $\\gamma$ is: (1/3+1/3)/((1-2/3)2/3+(1-2/3)2/3)=1.5 For the second leaf, we have four samples. $\\gamma$ is:(1/3-2/3-2/3+1/3)/(4(1-2/3)2/3)=-0.75 In Step 2.4, F(x) is updated. Now, let’s check another iteration 1iteration(1) The output is [1 2 1 1 1 1]for leaf 1, we have 5 related samples. and gamma is -0.31564962030401844for leaf 2, we have 1 related samples. and gamma is 1.9110594001952543 name popcorn age color y 𝑝1 𝑙1 𝑟1 𝛾1 𝑙2 𝑝2 0 Alex 1 10 Blue 1 0.869114 1.893147 0.130886 -0.315650 1.640627 0.837620 1 Brunei 1 90 Green 1 0.523270 0.093147 0.476730 1.911059 1.621995 0.835070 2 Candy 0 30 Blue 0 0.523270 0.093147 -0.523270 -0.315650 -0.159373 0.460241 3 David 1 30 Red 0 0.523270 0.093147 -0.523270 -0.315650 -0.159373 0.460241 4 Eric 0 30 Green 1 0.523270 0.093147 0.476730 -0.315650 -0.159373 0.460241 5 Felicity 0 10 Blue 1 0.869114 1.893147 0.130886 -0.315650 1.640627 0.837620 For Iteration 2, we have two leaves. For Leaf 1, there are 5 samples. And $\\gamma$ is (0.130886+-0.523270+-0.523270+0.476730+0.130886)/(20.869114(1-0.869114)+30.523270(1-0.523270))=-0.3156498224562022 For Leaf 2, there is only 1 sample. And 𝛾 is 0.476730/(0.523270*(1-0.523270))=1.9110593001700842 Let’s check another iteration 1iteration(2) The output: no name popcorn age color y 𝑝2 𝑙2 𝑟2 𝛾2 𝑙3 𝑝3 0 Alex 1 10 Blue 1 0.837620 1.640627 0.162380 1.193858 2.595714 0.930585 1 Brunei 1 90 Green 1 0.835070 1.621995 0.164930 -0.244390 1.426483 0.806353 2 Candy 0 30 Blue 0 0.460241 -0.159373 -0.460241 -0.244390 -0.354885 0.412198 3 David 1 30 Red 0 0.460241 -0.159373 -0.460241 -0.244390 -0.354885 0.412198 4 Eric 0 30 Green 1 0.460241 -0.159373 0.539759 -0.244390 -0.354885 0.412198 5 Felicity 0 10 Blue 1 0.837620 1.640627 0.162380 1.193858 2.595714 0.930585 Let’s call iteration 3 and 4 12iteration(3)iteration(4) Now, let’s take a look at the loss and accuracy: Accuracy: Loss: The code is here: https://github.com/EricWebsmith/machine_learning_from_scrach/blob/master/gradiant_boosting_classification.ipynb ReferenceGradient Boosting (Wikipedia) Gradient Boost Part 3: Classification — Youtube StatQuest Gradient Boost Part 4: Classification Details — Youtube StatQuest sklearn.tree.DecisionTreeRegressor — scikit-learn 0.21.3 documentation Understanding the decision tree structure — scikit-learn 0.21.3 documentation","categories":[],"tags":[{"name":"Gradient Boosting","slug":"Gradient-Boosting","permalink":"https://ericwebsmith.github.io/tags/Gradient-Boosting/"},{"name":"Boosting","slug":"Boosting","permalink":"https://ericwebsmith.github.io/tags/Boosting/"},{"name":"Classification","slug":"Classification","permalink":"https://ericwebsmith.github.io/tags/Classification/"}]},{"title":"Gradient Boosting Regression from Scratch","slug":"GradientBoostingRegression","date":"2020-04-12T06:44:42.000Z","updated":"2020-04-19T10:53:01.129Z","comments":true,"path":"2020/04/12/GradientBoostingRegression/","link":"","permalink":"https://ericwebsmith.github.io/2020/04/12/GradientBoostingRegression/","excerpt":"","text":"Gradient Boosting (GB) algorithm trains a series of weak learners and each focuses on the errors the previous learners have made and tries to improve it. Together, they make a better prediction. According to Wikipedia, Gradient boosting is a machine learning technique for regression and classification problems, which produces a prediction model in the form of an ensemble of weak prediction models, typically decision trees. It builds the model in a stage-wise fashion as other boosting methods do, and it generalizes them by allowing optimization of an arbitrary differentiable loss function. Prerequisite 1. Linear regression and gradient descent 2. Decision Tree After studying this post, you will be able to: 1. Explain gradient boosting algorithm. 2. Explain gradient boosting regression algorithm. 3. Write a gradient boosting regressor from scratch The algorithmThe following plot illustrates the algorithm. (Picture taken from Youtuber StatQuest with Josh Starmer) From the plot above, the first part is a stump, which is the average of y. We then add several trees to it. In the following trees, the target is not y. Instead, the target is the residual or the true value subtract previous prediction. residual=true\\_value - previous\\_predictionThat is why we say in Gradient Boosting trains a series of weak learners, each focuses on the errors of the previous one. The residual predictions are multiplied by the learning rate (0.1 here) before added to the average. The Steps Step 1: Calculate the average of y. The average is also the first estimation of y: \\bar{y}=\\frac{1}{n} \\sum_{i=1}^{n}y_i F_0(x)=\\bar{y}Step 2 for m in 1 to M: Step 2.1: Compute so-call pseudo-residuals: r_{im}=y_i-F_{m-1}(x_i) Step 2.2: Fit a regression tree t_m(x) to pseudo-residuals and create terminal regions (leafs) R_{jm} for j=1...Jm Step 2.3: For each leaf of the tree, there are $p_j$ elements, compute $\\gamma$ as the following equation. \\gamma_{im}=\\frac{1}{p_j} \\sum_{x_i \\in R_{jm}} r_{im} (In practice, the regression tree will do this for us.) Step 2.4: Update the model with learning rate $\\alpha$: F_m(x)=F_{m-1}+\\alpha\\gamma_m Step 3. Output F_M(x) In practise the regression tree will average the leaf for us. Thus, Step 2.2 and 2.3 can be combined into one step. And the steps can be simplified: New The Steps Step 1: Calculate the average of y. The average is also the first estimation of y: \\bar{y}=\\frac{1}{n} \\sum_{i=1}^{n}y_i F_0(x)=\\bar{y}Step 2 for m in 1 to M: Step 2.1: Compute so-call pseudo-residuals: r_{im}=y_i-F_{m-1}(x_i) Step 2.2: Fit a regression tree $t_m(x)$ to pseudo-residuals Step 2.3: Update the model with learning rate $\\alpha$: F_m(x)=F_{m-1}+\\alpha t_m(x) Step 3. Output F_M(x) (Optional) From Gradient Boosting to Gradient Boosting RegressionThe above knowledge is enough for writing BGR code from scratch. But I want to explain more about gradient boosting. GB is a meta-algorithm that can be applied to both regression and classification. The above one is only a specific form for regression. In the following, I will introduce the general gradient boosting algorithm and deduce GBR from GB. Let’s first look at the GB steps The Steps Input: training set \\{(x_i, y_i)\\}_{i=1}^{n}, a differentiable loss function L(y, F(x)), number of iterations M Algorithm: Step 1: Initialize model with a constant value: F_0(x)=\\underset{\\gamma}{\\operatorname{argmin}}\\sum_{i=1}^{n}L(y_i, \\gamma)Step 2 for m in 1 to M: Step 2.1: Compute so-call pseudo-residuals: r_{im}=-[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}]_{F(x)=F_{m-1}(x)} Step 2.2: Fit a weak learner h_m(x) to pseudo-residuals. and create terminal regions R_{jm}, for j=1...J_m Step 2.3: For each leaf of the tree, compute $\\gamma$ as following equation. \\gamma_{jm}=\\underset{\\gamma}{\\operatorname{argmin}}\\sum_{x_i \\in R_{jm}}^{n}L(y_i, F_{m-1}(x_i)+\\gamma) Step 2.4: Update the model with learning rate $\\alpha$: F_m(x)=F_{m-1}+\\alpha\\gamma_m Step 3. Output F_M(x) To deduce the GB to GBR, I simply define a loss function and solve the loss function in step 1, 2.1 and 2.3. We use sum of squared errror(SSE) as the loss function: L(y, \\gamma)=\\frac{1}{2}\\sum_{i=1}^{n}(y_i-\\gamma)^2For step 1: Because SSE is a convex and at the lowest point where the derivative is zero, we have the following: \\frac{\\partial L(y, F_0)}{\\partial F_0}=\\frac{\\partial \\frac{1}{2}\\sum_{i=1}^{n}(y_i-F_0)^2}{\\partial F_0} =\\sum_{i=1}^{n} (y_i-F_0)=0Thus, we have: F_0=\\frac{1}{n}\\sum_{i=1}^{n}y_iFor step 2.1: r_{im}=-[\\frac{\\partial L(y_i, F(x_i))}{\\partial F(x_i)}]_{F(x)=F_{m-1}(x)} =-[\\frac{\\partial \\frac{1}{2}\\sum_{i=1}^{n}(y_i-F_{m-1}(x_i))^2)}{\\partial F_{m-1}(x_i)}]_{F(x)=F_{m-1}(x)}(The chain rule) =--2*\\frac{1}{2}(y_i-F_{m-1}(x_i)) =y_i-F_{m-1}(x_i)For step 2.3: Similarly, the result is: \\gamma_{jm}=\\frac{1}{p_j}\\sum_{x_i \\in R_j}r_{im}CodeLet’s first import the modules. 12345678import pandas as pdfrom sklearn.tree import DecisionTreeRegressorfrom sklearn.datasets import load_bostonimport numpy as npimport matplotlib.pyplot as pltimport graphviz from sklearn import tree And load data. 1234567891011121314df=pd.DataFrame()df['name']=['Alex','Brunei','Candy','David','Eric','Felicity']df['height']=[1.6,1.6,1.5,1.8,1.5,1.4]df['gender']=['male','female','female','male','male','female']df['weight']=[88, 76, 56, 73, 77, 57]display(df)X=df[['height','gender']].copy()X.loc[X['gender']=='male','gender']=1X.loc[X['gender']=='female','gender']=0y=df['weight']display(X)n=df.shape[0] The data is display as: name height gender weight Alex 1.6 male 88 Brunei 1.6 female 76 Candy 1.5 female 56 David 1.8 male 73 Eric 1.5 male 77 Felicity 1.4 female 57 And X is: height gender 1.6 1 1.6 0 1.5 0 1.8 1 1.5 1 1.4 0 Step 1 Average1234567891011121314#now let's get startedlearning_rate=0.2loss = [0] * 6residuals = np.zeros([6,n])predictoin = np.zeros([6,n])#calculationaverage_y=y.mean()predictoin[0] = [average_y] * nresiduals[0] = y - predictoin[0]df['$f_0$']=predictoin[0]df['$r_0$']=residuals[0]display(df)loss[0] = np.sum(residuals[0] ** 2)trees = [] The average and residuals are as following: name height gender weight 𝑓0 𝑟0 0 Alex 1.6 male 88 71.166667 16.833333 1 Brunei 1.6 female 76 71.166667 4.833333 2 Candy 1.5 female 56 71.166667 -15.166667 3 David 1.8 male 73 71.166667 1.833333 4 Eric 1.5 male 77 71.166667 5.833333 5 Felicity 1.4 female 57 71.166667 -14.166667 In the first step, we calculate the average 71.2 as the initial prediction. The pseudo residuals are 16.8, 4.8, etc. Step 2 For LoopWe define each iteration as following and we will call it from i=0 to 5. 123456789101112131415161718def iterate(i): t = DecisionTreeRegressor(max_depth=1) t.fit(X,residuals[i]) trees.append(t) #next prediction, residual predictoin[i+1]=predictoin[i]+learning_rate * t.predict(X) residuals[i+1]=y-predictoin[i+1] loss[i+1] = np.sum(residuals[i+1] ** 2) df[f'$\\gamma_&#123;i+1&#125;$']=t.predict(X) df[f'$f_&#123;i+1&#125;$']=predictoin[i+1] df[f'$r_&#123;i+1&#125;$']=residuals[i+1] display(df[['name','height','gender','weight',f'$f_&#123;i&#125;$',f'$r_&#123;i&#125;$',f'$\\gamma_&#123;i+1&#125;$',f'$f_&#123;i+1&#125;$',f'$r_&#123;i+1&#125;$']]) dot_data = tree.export_graphviz(t, out_file=None, filled=True, rounded=True,feature_names=X.columns) graph = graphviz.Source(dot_data) display(graph) Iteration 0 name height gender weight 𝑓0 𝑟0 𝛾1 𝑓1 𝑟1 0 Alex 1.6 male 88 71.166667 16.833333 8.166667 72.800000 15.200000 1 Brunei 1.6 female 76 71.166667 4.833333 -8.166667 69.533333 6.466667 2 Candy 1.5 female 56 71.166667 -15.166667 -8.166667 69.533333 -13.533333 3 David 1.8 male 73 71.166667 1.833333 8.166667 72.800000 0.200000 4 Eric 1.5 male 77 71.166667 5.833333 8.166667 72.800000 4.200000 5 Felicity 1.4 female 57 71.166667 -14.166667 -8.166667 69.533333 -12.533333 In Iteration 0, we first train a tree using residuals_0. This tree tells us that males are higher than females, each male should add 8.167 kg, each female subtracts -8.167 kg. The result of the tree is \\gamma here. But, we want to take just a small step a time, so we multiply the learning rate \\alpha=0.2. Thus, the new prediction is prediction=prediction+\\alpha\\gamma. That is to say, for each male, he will add 8.167*0.2=1.6334 kg. For each female, she will lose -8.167*0.2=-1.6334 kg. Finally, the males are predicted 72.8 kg and females 69.5. Iteration 1 name height gender weight 𝑓1 𝑟1 𝛾2 𝑓2 𝑟2 0 Alex 1.6 male 88 72.800000 15.200000 7.288889 74.257778 13.742222 1 Brunei 1.6 female 76 69.533333 6.466667 7.288889 70.991111 5.008889 2 Candy 1.5 female 56 69.533333 -13.533333 -7.288889 68.075556 -12.075556 3 David 1.8 male 73 72.800000 0.200000 7.288889 74.257778 -1.257778 4 Eric 1.5 male 77 72.800000 4.200000 -7.288889 71.342222 5.657778 5 Felicity 1.4 female 57 69.533333 -12.533333 -7.288889 68.075556 -11.075556 In iteration 1, we firstly train a tree using residuals_1. This tree tells us height is also important in determining weight. Whose who are less than 1.55 meters are supported to lose -7.289 and the other to gain 7.289. Again, we want to shrink this to 20%, which is -1.4578 and 1.4578. We then make prediction_2 based on prediction_1 and \\gamma. We see Alex gains 1.4578 kg because he is 1.6. Other also gain or lose weight because of the new rule. Iteration 2 name height gender weight 𝑓2 𝑟2 𝛾3 𝑓3 𝑟3 0 Alex 1.6 male 88 74.257778 13.742222 6.047407 75.467259 12.532741 1 Brunei 1.6 female 76 70.991111 5.008889 -6.047407 69.781630 6.218370 2 Candy 1.5 female 56 68.075556 -12.075556 -6.047407 66.866074 -10.866074 3 David 1.8 male 73 74.257778 -1.257778 6.047407 75.467259 -2.467259 4 Eric 1.5 male 77 71.342222 5.657778 6.047407 72.551704 4.448296 5 Felicity 1.4 female 57 68.075556 -11.075556 -6.047407 66.866074 -9.866074 Iteration 2 again tells us that gender matters. Iteration 3 name height gender weight 𝑓3 𝑟3 𝛾4 𝑓4 𝑟4 0 Alex 1.6 male 88 75.467259 12.532741 5.427951 76.552849 11.447151 1 Brunei 1.6 female 76 69.781630 6.218370 5.427951 70.867220 5.132780 2 Candy 1.5 female 56 66.866074 -10.866074 -5.427951 65.780484 -9.780484 3 David 1.8 male 73 75.467259 -2.467259 5.427951 76.552849 -3.552849 4 Eric 1.5 male 77 72.551704 4.448296 -5.427951 71.466114 5.533886 5 Felicity 1.4 female 57 66.866074 -9.866074 -5.427951 65.780484 -8.780484 Iteration 3 argues that height is important, too. Iteration 4 name height gender weight 𝑓4 𝑟4 𝛾5 𝑓5 𝑟5 0 Alex 1.6 male 88 76.552849 11.447151 4.476063 77.448062 10.551938 1 Brunei 1.6 female 76 70.867220 5.132780 -4.476063 69.972007 6.027993 2 Candy 1.5 female 56 65.780484 -9.780484 -4.476063 64.885271 -8.885271 3 David 1.8 male 73 76.552849 -3.552849 4.476063 77.448062 -4.448062 4 Eric 1.5 male 77 71.466114 5.533886 4.476063 72.361326 4.638674 5 Felicity 1.4 female 57 65.780484 -8.780484 -4.476063 64.885271 -7.885271 Let’s stop at Iteration 4. And take a look at the loss. Hope you get the idea. The code is hosted at my github repo: https://github.com/EricWebsmith/machine_learning_from_scrach/blob/master/Gradiant_Boosting_Regression.ipynb Reference:https://en.wikipedia.org/wiki/Gradient_boosting https://www.youtube.com/watch?v=3CC4N4z3GJc&amp;list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&amp;index=44 https://www.youtube.com/watch?v=2xudPOBz-vs&amp;list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF&amp;index=45 This article is based on a video from StatQuest, I strongly recommend this Youtube channel.","categories":[],"tags":[{"name":"Gradient Boosting","slug":"Gradient-Boosting","permalink":"https://ericwebsmith.github.io/tags/Gradient-Boosting/"},{"name":"Boosting","slug":"Boosting","permalink":"https://ericwebsmith.github.io/tags/Boosting/"},{"name":"Regression","slug":"Regression","permalink":"https://ericwebsmith.github.io/tags/Regression/"}]},{"title":"Bayesian Optimization","slug":"BayesianOptimization","date":"2020-04-11T02:59:48.000Z","updated":"2020-04-12T06:52:45.484Z","comments":true,"path":"2020/04/11/BayesianOptimization/","link":"","permalink":"https://ericwebsmith.github.io/2020/04/11/BayesianOptimization/","excerpt":"","text":"According to Wikipedia, Bayesian optimization (BO) is a sequential design strategy for global optimization of black-box functions that do not require derivatives. Study ObjectiveIn this post, we will: Review optimization algorithms. Compare Bayesian optimization with gradient descent. Understand the process of Bayesian optimization. Write a simple Bayesian optimization algorithm from scratch. Use BO not from scratch. OptimizationOptimization is to find the global max or min from the function. Besides BO, we also use grid search, random search and gradient descent. The first two can be used on any function if computation power is not the problem. The third is used only if the function is convex and derivative. Bayesian optimization has no such limitations. However, the function is supposed to be smooth and continuous, otherwise, I would recommend grid search and random search. ProcessI think the whole process can be demonstrated as the following trinity: Here the objective function is the black function that we optimize. It produces samples (x, y). Usually, it is very costly to run the objective function, such that we introduce a surrogate function to predict the objective function. The prediction is mean and standard deviation of the objective function, which are used by the acquisition function in searching for the next x to explore or exploit. The next x is then consumed by the objective function. The loop goes on until the max or min is found. The surrogate function is usually the Gaussian process regressor while the acquisition function has many options. They are: Probability of Improvement (PI). Expected Improvement (EI). Upper/Lower Confidence Bound (LCB/UCB). Here we only focus on what we use, the UCB, the most straightforward one. If we ignore weight, UCB can be written as: 𝑈𝐶𝐵(𝑥)=𝜇(𝑥)+𝜎(𝑥) 𝑥=argmax 𝑈𝐶𝐵(𝑥) We do all of this inside the search space. The whole process: Initiate x with the min and max of the search space. Calculate y using x and objective function. Fit the surrogate function. Find new x using the acquisition function. Go to 1 Python CodeLet’s first define and plot the objective function as following: 12def objective(x): return ((x-0.47)**2 * math.sin(3 * x)) Here the maximum (x=0.87, y= 0.0811051) is also plotted as a blue point. Now, this function is non-convex, thus gradient descent cannot be used. We use BO. The surrogate function is the Gaussian process regressor and UCB is used as the acquisition function. 12345678910111213#uppper confidence bound (UCB)#beta = 1def acquisition(mean, std): mean=mean.flatten() #UCB upper=mean+std #argmax max_at=np.argmax(upper) return X[max_at]#surrogatesurrogate = GaussianProcessRegressor() Code for the whole process 123456789101112131415161718192021#step 0 Initiate x with the min and max of the search space.xsamples=np.array([[0],[1]])#step 1 Calculate y using x and objective function.ysamples=np.array([objective(x) for x in xsamples])for i in range(4): #step 2 Fit the surrogate function. surrogate.fit(xsamples, ysamples) mean, std=surrogate.predict(X, return_std=True) #step 3 Find new x using acquisition function. new_x=acquisition(mean, std) #step 4 Go to 1 new_y=objective(new_x) #plot plot(X, y, xsamples, ysamples, mean, std, new_x, new_y, i) xsamples=np.vstack((xsamples, new_x)) ysamples=np.vstack((ysamples, new_y)) Step 0: In step 0, we simply produce two sample x=0 and x=1. Iteration 0: In iteration 0, the two samples are used by the surrogate function to generate mean and std(green). The acquisition function finds the max UCB when x=0.53(red). Objective(0.53) is 0.00359934. Now a new point (0.53, 0.00359934) is found. We give the three points to iteration 1. Iteration 1: Iteration 2: Iteration 3: The new point(red) here is (0.53, 0.00359934) and it is just the max. We can see that BO can find the optimum in just 4 iterations. And we call the objective function only 6 times. If we use the grid search, that will be 100 times. The complete version of the code can be found here: https://github.com/EricWebsmith/machine_learning_from_scrach/blob/master/bayesian_optimization.ipynb Bayesian Optimization not from scratchThere are many tools for BO. One of them is Hyperopt. The following is just a simple demonstration of that. 1234567from hyperopt import fmin, tpe, hpbest = fmin( fn=lambda x:-objective(x), space=hp.uniform('x', 0, 1), algo=tpe.suggest, max_evals=100)print(best) Referencehttps://en.wikipedia.org/wiki/Bayesian_optimization","categories":[],"tags":[{"name":"AutoML","slug":"AutoML","permalink":"https://ericwebsmith.github.io/tags/AutoML/"},{"name":"Optimization","slug":"Optimization","permalink":"https://ericwebsmith.github.io/tags/Optimization/"}]},{"title":"AutoML Introduction","slug":"automl","date":"2020-04-03T16:29:50.000Z","updated":"2020-04-11T05:58:53.480Z","comments":true,"path":"2020/04/04/automl/","link":"","permalink":"https://ericwebsmith.github.io/2020/04/04/automl/","excerpt":"","text":"With the development of machine learning, demand for AutoML (Automatic Machine Learning) increases. This article split this topic into two, namely AutoML in classic machine learning and that in deep learning. After completing this tutorial, you will know: AutoML in both classic and deep machine learning. A peek of two open-source frameworks, Auto-Sklearn and Auto-Keras. Two algorithms, Bayesian Optimization and Network Morphism. The ideas behind Neural Architecture Search. AutoML in Classic Machine LearningCASHAutoML has many sub-functionalities, including automatic data analysis, automatic feature engineering, automatic normalization and regularization, automatic feature selection, automatic algorithm selection and automatic hyperparameter optimization(HPO). Recent studies focus on the CASH[1] problem. That is Combined Algorithm and Selection and Hyperparameter Optimization. CASH was proposed by Thornton in Auto-Weka[1]. The solution he provided was Bayesian Optimization[2]. Bayesian OptimizationBayesian Optimization (BO) is one of the means we find extrema (both max and min values) in a function. Other options may include grid search, random search and gradient descent. Compared to gradient descent, BO optimizes functions that are non-convex and non-derivative. In BO, we call the black-box function we optimize the objective function. This function is usually costly to run. Thus, we introduce the surrogate function to estimate the mean and standard deviation of the objective function. The output is then used by the acquisition function in searching for the next sample to exploit or explore. The BO searches for extrema in a finite search space. The process is summarized as follow: Sample some points x in the search space. Find the corresponding y by the objective function. update the surrogate function using x, y. find the next x using the acquisition function. Goto 2 unless finding extrema. The following flowchart demonstrates the process. Now let’s look at an example. Suppose we have the following function: The search space is [0, 1]. Firstly two points x=0 and x=1 are selected, and their y values are calculated using the objective function. Then the mean and standard deviation are generated by the Gaussian process or the surrogate function. The UCB (Upper Confidence Bound) algorithm is used as the acquisition function. It simply takes the max value of the upper confidence bound (red in the plot) as the next sample point. The BO continues… After four iterations, the max value is found. The above pictures were generated by a notebook from my Github Repo Machine Learning Step by Step. Auto-SklearnAuto-Sklearn[3] used Bayesian Optimization to find the best hyperparameters for machine learning. Besides that, it proposed two new improvements. The first is meta-learning. Auto-Sklearn collected several datasets, extracted features from these datasets. These datasets are trained and the best hyperparameters are collected. The dataset features and best hyperparameters are treated as input and output for machine learning and the relationship is learned. Thus, the search space is narrow and the algorithm runs faster. The second improvement is ensemble. As we all know ensemble improves accuracy. I installed Auto-Sklearn. The Titanic Survive and Boston House Price datasets are used. Each took one hour to finish on an i7 CPU. The scores are 0.76 and 0.85. Not too bad. Auto-Sklearn focuses on the CASH problem. it does not handle data preprocessing. I have to remove string features like names and tickets in advance. Categorical features like embarking place, gender have to be transformed into Boolean values or one-hot values. Sample code for auto-sklearn 1234import autosklearn.classificationcls = autosklearn.classification.AutoSklearnClassifier()cls.fit(X_train, y_train)predictions = cls.predict(X_test) Official Website: https://automl.github.io/auto-sklearn/master/ Deep Learning in AutoMLNeural Architecture SearchNeural Architecture Search (NAS) is the main research topic in deep learning automation. The rough idea is to treat deep models as strings such that the next layer can be predicted by RNN. NAS named this RNN the controller. The original NAS used reinforcement learning to optimize the parameters. Some architectures have branches. NAS uses a batch of bi-classifiers to determine if Layer N connects to one of the N-1 layers. The following are the original LSTM (upper left) and two LSTM structures NAS found. Xin He[5] summarized all the NAS works. For controllers, grid search, random search, reinforcement learning, evolution algorithm, Bayesian optimization, gradient descent are used. Low fidelity, transfer learning, surrogate, early stopping are used to perform more efficiently. The following is a comparison of all the NAS implementations: Network MorphismIn the process of NAS, a great number of architectures are tested. If the new network can learn parameters from the old ones, it would be more efficient. Network Morphism[6] provides such a mechanism. Network Morphism named the old and new network the parent network and the child network. The child network inherits knowledge from the parent network. There are five cases in Network Morphism, linear, non-linear, stand-alone width, stand-alone kernal, and subnet. Linear Case A new layer, Layer L is inserted between Layer L-1 and Layer L+1. Bl-1 and Bl+1 are two matrices and Bl+1=Bl-1 * G. To insert a new layer, we simply split G into two matrices, Fl and Fl+1 . Non-Linear Case To insert a non-linear layer between two layers, a new activation function, parametric activation is introduced. It starts as an Identity matrix and learns to become an activation function afterward. It is a wrapper around other activation functions. The equation is as follow: Stand-alone Width We calculate the equations from the above chart. We finally will have the following: Kernal For kernals, we simply do padding. Subnet Firstly, we insert the layers one by one. this is sequential subnet morphing. We then stack them by simply split G into a group of G, each is G/n. Auto-KerasAuto-Keras is an opensource based on Keras. It uses Bayesian optimization and network morphism. It trains CNN, RNN and traditional DNN. Sample code: 12345import autokeras as akclf = ak.ImageClassifier()clf.fit(x_train, y_train)results = clf.predict(x_test) The official website: https://autokeras.com/ Where to use AutoML?AutoML is suitable in some mature scenarios, like traditional ML, image recognition, object detection, OCR, text analysis, etc.. The reason is that we have limit options. For problems like audio-related research, because it is not mature, what is to try is not clear. Thus it is not possible to use autoML. Reference[1] C. Thornton, F. Hutter, H. Hoos, and K. Leyton-Brown. Auto-WEKA: combined selection and hyperparameter optimization of classification algorithms. In Proc. of KDD’13, pages 847–855, 2013. [2] E. Brochu, V. Cora, and N. de Freitas. A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. CoRR, abs/1012.2599, 2010. [3] Efficient and Robust Automated Machine Learning, Feurer et al., Advances in Neural Information Processing Systems 28 (NIPS 2015). [4] Zoph, Barret, and Quoc V. Le. “Neural Architecture Search with Reinforcement Learning.” arXiv: Learning (2016). [5] He, Xin, Kaiyong Zhao, and Xiaowen Chu. “AutoML: A Survey of the State-of-the-Art..” arXiv: Learning (2019). [6] Wei, Tao, et al. “Network morphism.” international conference on machine learning (2016): 564-572.","categories":[],"tags":[{"name":"AutoML","slug":"AutoML","permalink":"https://ericwebsmith.github.io/tags/AutoML/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://ericwebsmith.github.io/tags/Deep-Learning/"}]}],"categories":[],"tags":[{"name":"Gradient Boosting","slug":"Gradient-Boosting","permalink":"https://ericwebsmith.github.io/tags/Gradient-Boosting/"},{"name":"Boosting","slug":"Boosting","permalink":"https://ericwebsmith.github.io/tags/Boosting/"},{"name":"Classification","slug":"Classification","permalink":"https://ericwebsmith.github.io/tags/Classification/"},{"name":"Regression","slug":"Regression","permalink":"https://ericwebsmith.github.io/tags/Regression/"},{"name":"AutoML","slug":"AutoML","permalink":"https://ericwebsmith.github.io/tags/AutoML/"},{"name":"Optimization","slug":"Optimization","permalink":"https://ericwebsmith.github.io/tags/Optimization/"},{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://ericwebsmith.github.io/tags/Deep-Learning/"}]}